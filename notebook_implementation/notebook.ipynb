{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "from typing import TypedDict, List, Annotated, Literal, Union\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import operator\n",
    "\n",
    "from langgraph.types import Command, Send\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal, Dict, Any\n",
    "from enum import Enum\n",
    "\n",
    "import uuid\n",
    "\n",
    "from tavily import TavilyClient\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_llm(\n",
    "        provider: Literal[\"openai\", \"anthropic\", \"google\", \"ollama\"],\n",
    "        model: str,\n",
    "        temperature: float = 0.5,\n",
    "):\n",
    "    if provider == \"openai\":\n",
    "        return ChatOpenAI(model=model, temperature=temperature)\n",
    "    elif provider == \"anthropic\":\n",
    "        return ChatAnthropic(model=model, temperature=temperature)\n",
    "    elif provider == \"google\":\n",
    "        return ChatGoogleGenerativeAI(model=model, temperature=temperature)\n",
    "    elif provider == \"ollama\":\n",
    "        return ChatOllama(model=model, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_llm(\n",
    "    provider=\"openai\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FieldType(str, Enum):\n",
    "    string = \"string\"\n",
    "    number = \"number\"\n",
    "    array = \"array\"\n",
    "    boolean = \"boolean\"\n",
    "\n",
    "class SchemaField(BaseModel):\n",
    "    key: str = Field(..., description=\"The unique identifier for the field\")\n",
    "    type: FieldType = Field(..., description=\"The data type of the field\")\n",
    "    description: str = Field(..., description=\"Some descriptive information for the field\")\n",
    "\n",
    "class DatasetSchema(BaseModel):\n",
    "    generated_schema: list[SchemaField]\n",
    "\n",
    "class DatasetRecords(BaseModel):\n",
    "    dataset: List[Dict[str, Any]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section(BaseModel):\n",
    "    section_name: str = Field(..., description=\"The name of this section of the report without its number\")\n",
    "    sub_sections: List[str] = Field(..., description=\"Comprehensive descriptions of sub-sections, each combining the sub-section title and its bullet points into a fluid, natural-language description\")\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(..., description=\"A list of sections\")\n",
    "\n",
    "class Query(BaseModel):\n",
    "    query: str = Field(..., description=\"A search query\")\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[Query] = Field(..., description=\"A list of search queries\")\n",
    "\n",
    "class SearchResult(BaseModel):\n",
    "    query: Query = Field(..., description=\"The search query that was used to retrieve the raw content\")\n",
    "    raw_content: list[str] = Field(..., description=\"The raw content retrieved from the search\")\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    feedback: Union[str, bool] = Field(..., description=\"Feedback on the report structure. If the content is good for the section, return True (boolean), otherwise return a string of feedback on what is missing or incorrect.\")\n",
    "\n",
    "class SectionOutput(BaseModel):\n",
    "    # final_section_content: List[str] = Field(..., description=\"The final section content\")\n",
    "    final_section_dataset: List[Dict[str, Any]] = Field(..., description=\"The final section dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    topic: str\n",
    "    outline: str\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    report_structure: str\n",
    "    sections: List[Section]\n",
    "    final_section_dataset: Annotated[List[Dict[str, Any]], operator.add] = []\n",
    "    final_dataset: List[Dict[str, Any]]\n",
    "    schema: DatasetSchema\n",
    "\n",
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    report_structure: str\n",
    "    section: Section\n",
    "    knowledge: str\n",
    "    reflection_feedback: Feedback = Feedback(feedback=\"\")\n",
    "    generated_queries: List[Query] = []\n",
    "    searched_queries: Annotated[List[Query], operator.add] = []\n",
    "    search_results: Annotated[List[SearchResult], operator.add] = []\n",
    "    accumulated_content: str = \"\"\n",
    "    reflection_count: int = 1\n",
    "    final_section_content: List[str] = []\n",
    "    schema: DatasetSchema\n",
    "    final_section_dataset: List[Dict[str, Any]] = []\n",
    "    error: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_GENERATION_PROMPT = \"\"\"You are an autonomous schema-generating agent designed to construct data schemas for fine-tuning or training LLMs on user-specified tasks. Your jobis to analyze the user's task description and output a structured dataset schema definition.\n",
    "\n",
    "Ensure each field in the schema is useful for training and fine-tuning, well-typed, and annotated. Focus on tasks involving natural language input, structured context (like database schemas), and model output (like SQL queries, code, responses, etc.).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_schema_generator_system_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(SCHEMA_GENERATION_PROMPT),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        template=\"\"\"\n",
    "        Topic: {topic}\n",
    "        Outline: {outline}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "llm_with_schema_tool = llm.bind_tools(tools=[DatasetSchema], tool_choice=\"required\")\n",
    "schema_generator_llm = dataset_schema_generator_system_prompt | llm_with_schema_tool\n",
    "\n",
    "def schema_generator_node(state: AgentState, config: RunnableConfig):\n",
    "    result = schema_generator_llm.invoke(state)\n",
    "    suggested_schema = DatasetSchema.model_validate(result.tool_calls[0][\"args\"])\n",
    "\n",
    "    return {\"schema\": suggested_schema, \"messages\": f\"{[suggested_schema.generated_schema]}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback_on_schema_node(state: AgentState, config: RunnableConfig) -> Command[Literal[\"report_structure_planner\", \"schema_generator\"]]:\n",
    "    human_message = input(\"Please provide feedback on the report structure (type 'continue' to continue): \")\n",
    "    schema = state.get(\"schema\")\n",
    "    if human_message == \"continue\":\n",
    "        return Command(\n",
    "            goto=\"report_structure_planner\",\n",
    "            update={\"messages\": [HumanMessage(content=human_message)], \"schema\": schema}\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            goto=\"schema_generator\",\n",
    "            update={\"messages\": [HumanMessage(content=human_message)]}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_STRUCTURE_PLANNER_SYSTEM_PROMPT_TEMPLATE = \"\"\"You are an expert research assistant specialized in creating structured research frameworks. Your primary task is to generate a detailed, appropriate report structure based on a user's research topic and brief outline.\n",
    "\n",
    "## Process to Follow:\n",
    "\n",
    "1. UNDERSTAND THE REQUEST:\n",
    "   - Carefully analyze the topic and outline provided by the user\n",
    "   - Identify the type of research needed (exploratory, comparative, analytical, etc.)\n",
    "   - Recognize the domain/field of the research\n",
    "\n",
    "2. ASK CLARIFYING QUESTIONS:\n",
    "   - If the user's request lacks sufficient detail, ask 2-3 focused questions to better understand:\n",
    "     * Their background and expertise level\n",
    "     * Their specific goals for the research\n",
    "     * Any particular aspects they want to emphasize\n",
    "     * Intended audience and purpose of the report\n",
    "   - Prioritize questions that will significantly impact the report structure\n",
    "\n",
    "3. GENERATE A COMPREHENSIVE REPORT STRUCTURE:\n",
    "   - Create a detailed, hierarchical structure with:\n",
    "     * Clear main sections (typically 5-12 depending on topic complexity)\n",
    "     * Relevant subsections under each main section\n",
    "     * Logical flow from introduction to conclusion\n",
    "   - Adapt the structure to match the specific research type:\n",
    "     * For learning/exploration topics: progress from fundamentals to advanced concepts\n",
    "     * For comparison topics: use parallel structure across compared items\n",
    "     * For data source exploration: organize by data types, sources, and methodologies\n",
    "     * For implementation topics: follow a logical sequence from setup to advanced usage\n",
    "   - Ensure the structure is comprehensive but focused on the user's specific needs\n",
    "\n",
    "4. FORMAT THE RESPONSE:\n",
    "   - Present the report structure as a hierarchical outline with clear section numbering\n",
    "   - Use descriptive titles for each section and subsection\n",
    "   - Include brief descriptions of key sections when helpful\n",
    "   - Provide the structure in a clean, easy-to-read format\n",
    "\n",
    "5. OFFER FOLLOW-UP ASSISTANCE:\n",
    "   - Ask if any sections need adjustment or elaboration\n",
    "   - Suggest specific modifications if you identify potential improvements\n",
    "\n",
    "Remember that your task is ONLY to create the report structure, not to produce the actual research content. Focus on creating a comprehensive framework that will guide the user's research efforts.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_structure_planner_system_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(REPORT_STRUCTURE_PLANNER_SYSTEM_PROMPT_TEMPLATE),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        template=\"\"\"\n",
    "        Topic: {topic}\n",
    "        Outline: {outline}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "report_structure_planner_llm = report_structure_planner_system_prompt | llm\n",
    "\n",
    "def report_structure_planner_node(state: AgentState, config: RunnableConfig):\n",
    "    result = report_structure_planner_llm.invoke(state)\n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback_node(state: AgentState, config: RunnableConfig)->Command[Literal[\"section_formatter\", \"report_structure_planner\"]]:\n",
    "    human_message = input(\"Please provide feedback on the report structure (type 'continue' to continue): \")\n",
    "    report_structure = state.get(\"messages\")[-1].content\n",
    "    if human_message == \"continue\":\n",
    "        return Command(\n",
    "            goto=\"section_formatter\",\n",
    "            update={\"messages\": [HumanMessage(content=human_message)], \"report_structure\": report_structure}\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            goto=\"report_structure_planner\",\n",
    "            update={\"messages\": [HumanMessage(content=human_message)]}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_FORMATTER_SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a specialized parser that converts hierarchical report structures into a structured format. Your task is to analyze a report structure outline and extract the sections and subsections, while condensing the detailed bullet points into comprehensive subsection descriptions.\n",
    "\n",
    "## Your Input:\n",
    "You will receive a message containing a report structure with numbered sections and subsections, along with descriptive bullet points.\n",
    "\n",
    "## Your Output Format:\n",
    "You must output the result in the presented structure\n",
    "\n",
    "# Processing Instructions:\n",
    "\n",
    "- Identify each main section (typically numbered as 1, 2, 3, etc.)\n",
    "- Extract the main section title without its number (e.g., \"Introduction\" from \"1. Introduction\")\n",
    "- For each main section, identify all its subsections (typically numbered as 1.1, 1.2, 2.1, 2.2, etc.)\n",
    "- For each subsection, incorporate its title AND the descriptive bullet points beneath it into a single comprehensive description\n",
    "- Combine related concepts using commas and connecting words (and, with, including, etc.)\n",
    "- Organize these into a JSON array with each object containing:\n",
    "  \"section_name\": The main section title\n",
    "  \"sub_sections\": An array of comprehensive subsection descriptions\n",
    "\n",
    "# Content Condensation Guidelines:\n",
    "\n",
    "- Transform subsection titles and their bullet points into fluid, natural-language descriptions\n",
    "- Include all key concepts from the bullet points, but phrase them as part of a cohesive description\n",
    "- Use phrases like \"overview of\", \"including\", \"focusing on\", \"covering\", etc. to connect concepts\n",
    "- Maintain the key terminology from the original structure\n",
    "- Aim for descriptive phrases rather than just lists of topics\n",
    "\n",
    "# Example Transformation:\n",
    "## From:\n",
    "1. Introduction\n",
    "   - 1.1 Background of Machine Learning\n",
    "     - Overview of machine learning concepts\n",
    "     - Importance of algorithms in machine learning\n",
    "   - 1.2 Introduction to Support Vector Machines\n",
    "     - Definition and significance\n",
    "     - Historical context and development\n",
    "To:\n",
    "{{\n",
    "  \"section_name\": \"Introduction\",\n",
    "  \"sub_sections\": [\n",
    "    \"Background, overview and importance of Machine Learning\", \n",
    "    \"Introduction to Support Vector Machines, definition, significance and historical context\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Remember to output only the valid JSON array containing all processed sections, with no additional commentary or explanations in your response.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "section_formatter_system_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(SECTION_FORMATTER_SYSTEM_PROMPT_TEMPLATE),\n",
    "    HumanMessagePromptTemplate.from_template(template=\"{report_structure}\"),\n",
    "])\n",
    "\n",
    "section_formatter_llm = section_formatter_system_prompt | llm.with_structured_output(Sections)\n",
    "\n",
    "def section_formatter_node(state: AgentState, config: RunnableConfig) -> Command[Literal[\"research_agent\"]]:\n",
    "    result = section_formatter_llm.invoke(state)\n",
    "    schema = state.get(\"schema\")\n",
    "    report_structure = state.get(\"report_structure\")\n",
    "    topic = state.get(\"topic\")\n",
    "    # return {\"sections\": result.sections}\n",
    "    return Command(\n",
    "        update={\"sections\": result.sections},\n",
    "        goto=[\n",
    "            Send(\n",
    "                \"research_agent\",\n",
    "                {\n",
    "                    \"topic\": topic,\n",
    "                    \"section\": s,\n",
    "                    \"schema\": schema,\n",
    "                    \"report_structure\": report_structure,\n",
    "                }\n",
    "            ) for s in result.sections\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_KNOWLEDGE_SYSTEM_PROMPT_TEMPLATE = \"\"\"You are an expert research content generator. Your task is to create comprehensive, accurate, and well-structured content for a specific section of a research report. You will be provided with a section name and its subsections, and you should use your knowledge to create detailed content covering all aspects described.\n",
    "\n",
    "## Input Format:\n",
    "You will receive a section object with the following structure:\n",
    "```json\n",
    "{{\n",
    "  \"section_name\": \"The main section title\",\n",
    "  \"sub_sections\": [\n",
    "    \"Comprehensive description of subsection 1 including key points to cover\",\n",
    "    \"Comprehensive description of subsection 2 including key points to cover\",\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "## Your Task:\n",
    "Generate thorough, accurate content for this section that:\n",
    "\n",
    "1. Begins with a brief introduction to the section topic\n",
    "2. Covers each subsection in depth, maintaining the order provided\n",
    "3. Includes relevant examples, explanations, and context\n",
    "4. Incorporates current understanding and established knowledge on the topic\n",
    "5. Maintains an academic and informative tone appropriate for a research report\n",
    "6. Uses appropriate headings and subheadings for structure\n",
    "\n",
    "## Content Guidelines:\n",
    "\n",
    "### Depth and Breadth:\n",
    "- Aim for comprehensive coverage of each subsection\n",
    "- Include definitions of key terms and concepts\n",
    "- Discuss current understanding and applications\n",
    "- Address relationships between different concepts\n",
    "\n",
    "### Structure:\n",
    "- Use hierarchical formatting with clear headings\n",
    "- Format the section title as a level 2 heading (##)\n",
    "- Format each subsection as a level 3 heading (###)\n",
    "- Use paragraphs to organize information logically\n",
    "- Include transitional phrases between subsections\n",
    "\n",
    "### Content Quality:\n",
    "- Prioritize accuracy and clarity\n",
    "- Provide specific examples to illustrate concepts\n",
    "- Include relevant data points, statistics, or findings when applicable\n",
    "- Maintain an objective, scholarly tone\n",
    "- Avoid oversimplification of complex topics\n",
    "\n",
    "### Technical Considerations:\n",
    "- Use markdown formatting for headings, lists, and emphasis\n",
    "- Include appropriate technical terminology\n",
    "- Define specialized terms when they first appear\n",
    "- Use code snippets or mathematical notation if appropriate for the topic\n",
    "\n",
    "## Output Format:\n",
    "Return only the generated content with appropriate markdown formatting. Do not include meta-commentary about your process or limitations. Your output should be ready to be inserted directly into the research report as a complete section.\n",
    "\n",
    "Remember to rely solely on your existing knowledge. Do not fabricate specific studies, statistics, or quotations that you cannot verify.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_knowledge_system_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(SECTION_KNOWLEDGE_SYSTEM_PROMPT_TEMPLATE),\n",
    "    HumanMessagePromptTemplate.from_template(template=\"{section}\"),\n",
    "])\n",
    "\n",
    "section_knowledge_llm = section_knowledge_system_prompt | llm\n",
    "\n",
    "def section_knowledge_node(state: ResearchState, config: RunnableConfig):\n",
    "    result = section_knowledge_llm.invoke(state)\n",
    "    return {\"knowledge\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_GENERATOR_SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a specialized search query generator for a research assistant system. Your task is to create highly effective search queries based on research section information. These queries will be used to retrieve relevant information from web search APIs to enhance research report content.\n",
    "\n",
    "## Section Structure:\n",
    "```json\n",
    "{{\n",
    "  \"section_name\": \"The main section title\",\n",
    "  \"sub_sections\": [\n",
    "    \"Comprehensive description of subsection 1 including key points to cover\",\n",
    "    \"Comprehensive description of subsection 2 including key points to cover\",\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "## Your Task:\n",
    "Generate up to {max_queries} effective search queries that will retrieve the most relevant information for the given section and its subsections.\n",
    "\n",
    "## Query Generation Process:\n",
    "\n",
    "### For Initial Runs (no previous_queries or reflection_feedback):\n",
    "1. Analyze the section name and all subsection descriptions thoroughly\n",
    "2. Identify the core concepts, key terms, and relationships that need to be researched\n",
    "3. Prioritize fundamental information needs first\n",
    "4. Create specific, targeted queries for the most important information\n",
    "5. Ensure coverage across all subsections, but prioritize depth over breadth\n",
    "6. Include technical terminology and domain-specific language when appropriate\n",
    "\n",
    "### For Subsequent Runs (with reflection_feedback):\n",
    "1. Carefully analyze the reflection feedback to understand information gaps\n",
    "2. Prioritize queries that address the specific missing information\n",
    "3. Avoid generating queries too similar to previous_queries\n",
    "4. Create more specialized or alternative phrasings to find the missing information\n",
    "5. Use more technical or specific terminology if general queries were insufficient\n",
    "\n",
    "## Query Construction Guidelines:\n",
    "\n",
    "1. **Specificity**: Create targeted queries that are likely to return relevant results\n",
    "   - Include specific technical terms rather than general descriptions\n",
    "   - Incorporate domain knowledge and specialized terminology\n",
    "\n",
    "2. **Diversity**: Ensure variety in your query approaches\n",
    "   - Vary query structure (questions, keyword sets, specific facts to verify)\n",
    "   - Target different aspects of the subsections\n",
    "   - Include different perspectives or viewpoints when relevant\n",
    "\n",
    "3. **Prioritization**: Order queries by importance\n",
    "   - Place queries for fundamental or critical information first\n",
    "   - Prioritize queries addressing explicit reflection feedback\n",
    "   - Ensure the most important subsections are covered in the limited query count\n",
    "\n",
    "4. **Effectiveness**: Optimize for search engine performance\n",
    "   - Use search operators when helpful (quotes for exact phrases, etc.)\n",
    "   - Keep queries concise but descriptive (typically 4-10 words)\n",
    "   - Include year/recency indicators for time-sensitive topics\n",
    "\n",
    "Remember: The most important queries should come first in your list, as the system may only use a subset of your generated queries based on the user's `max_queries` setting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query_generator_node(state: ResearchState, config: RunnableConfig):\n",
    "    query_generator_system_prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(QUERY_GENERATOR_SYSTEM_PROMPT_TEMPLATE),\n",
    "        HumanMessagePromptTemplate.from_template(template=\"Section: {section}\\nPrevious Queries: {searched_queries}\\nReflection Feedback: {reflection_feedback}\"),\n",
    "    ])\n",
    "\n",
    "    query_generator_llm = query_generator_system_prompt | llm.with_structured_output(Queries)\n",
    "    state.setdefault(\"reflection_feedback\", \"\")\n",
    "    state.setdefault(\"searched_queries\", [])\n",
    "    configurable = config.get(\"configurable\")\n",
    "\n",
    "    input_data = {\n",
    "        **state,\n",
    "        **configurable  # includes max_queries, search_depth, etc.\n",
    "    }\n",
    "\n",
    "    result = query_generator_llm.invoke(input_data, configurable)\n",
    "    return {\"generated_queries\": result.queries, \"searched_queries\": result.queries}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_client = TavilyClient()\n",
    "\n",
    "def tavily_search_node(state: ResearchState, config: RunnableConfig):\n",
    "    queries = state[\"generated_queries\"]\n",
    "    configurable = config.get(\"configurable\")\n",
    "    search_results = []\n",
    "    for query in queries:\n",
    "        raw_content = []\n",
    "        response = tavily_client.search(query=query.query, max_results=configurable.get(\"search_depth\"), include_raw_content=True)\n",
    "        for result in response[\"results\"]:\n",
    "            raw_content.append(result['content'])\n",
    "        search_results.append(SearchResult(query=query, raw_content=raw_content))\n",
    "    return {\"search_results\": search_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ACCUMULATOR_SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a specialized agent responsible for curating and synthesizing raw search results. Your task is to transform unstructured web content into coherent, relevant, and organized information that can be used for report generation.\n",
    "\n",
    "## Input\n",
    "You will receive a list of SearchResult objects, each containing:\n",
    "1. A Query object with the search query that was used\n",
    "2. A list of raw_content strings containing text extracted from web pages\n",
    "\n",
    "## Process\n",
    "For each SearchResult provided:\n",
    "\n",
    "1. ANALYZE the raw_content to identify:\n",
    "   - Key information relevant to the associated query\n",
    "   - Main concepts, definitions, and relationships\n",
    "   - Supporting evidence, statistics, or examples\n",
    "   - Credible sources or authorities mentioned\n",
    "\n",
    "2. FILTER OUT:\n",
    "   - Irrelevant website navigation elements and menus\n",
    "   - Advertisements and promotional content\n",
    "   - Duplicate information\n",
    "   - Footers, headers, and other website template content\n",
    "   - Form fields, subscription prompts, and UI text\n",
    "   - Clearly outdated information\n",
    "\n",
    "3. ORGANIZE the information into:\n",
    "   - Core concepts and definitions\n",
    "   - Key findings and insights\n",
    "   - Supporting evidence and examples\n",
    "   - Contrasting viewpoints (if present)\n",
    "   - Contextual background information\n",
    "\n",
    "4. SYNTHESIZE the content by:\n",
    "   - Consolidating similar information from multiple sources\n",
    "   - Resolving contradictions where possible (noting them explicitly otherwise)\n",
    "   - Ensuring logical flow of information\n",
    "   - Maintaining appropriate context\n",
    "\n",
    "## Guidelines\n",
    "- Focus on accuracy and relevance\n",
    "- Maintain neutrality and balance in presenting information\n",
    "- Preserve technical precision when dealing with specialized topics\n",
    "- Note explicitly when information appears contradictory or uncertain\n",
    "- When information appears to be from commercial sources, note potential bias\n",
    "- Prioritize more recent information over older content\n",
    "- Maintain proper attribution when specific sources are referenced\n",
    "- NO IMPORTANT DETAILS SHOULD BE LEFT OUT. BE DETAILED AND THOROUGH.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def result_accumulator_node(state: ResearchState, config: RunnableConfig):\n",
    "    result_accumulator_system_prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(RESULT_ACCUMULATOR_SYSTEM_PROMPT_TEMPLATE),\n",
    "        HumanMessagePromptTemplate.from_template(template=\"{search_results}\"),\n",
    "    ])\n",
    "\n",
    "    result_accumulator_llm = result_accumulator_system_prompt | llm\n",
    "    result = result_accumulator_llm.invoke(state)\n",
    "    return {\"accumulated_content\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_FEEDBACK_SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a specialized agent responsible for critically evaluating search result content against report section requirements. You determine whether the accumulated content sufficiently addresses the intended section scope or requires additional information.\n",
    "\n",
    "## Input\n",
    "You will receive:\n",
    "1. A Section object containing:\n",
    "   - section_name: The name of the section without its number\n",
    "   - sub_sections: A list of comprehensive descriptions of sub-sections\n",
    "2. Accumulated content from search results related to this section\n",
    "\n",
    "## Process\n",
    "Carefully analyze the relationship between the section requirements and the accumulated content:\n",
    "\n",
    "1. ASSESS COVERAGE by identifying:\n",
    "   - How well the accumulated content addresses each sub-section\n",
    "   - Key concepts or topics from the sub-sections that are missing in the content\n",
    "   - Depth and breadth of information relative to what the section requires\n",
    "   - Presence of all necessary perspectives, examples, and supporting evidence\n",
    "\n",
    "2. EVALUATE QUALITY by considering:\n",
    "   - Accuracy and currency of the information\n",
    "   - Relevance to the specific section requirements\n",
    "   - Logical organization and flow\n",
    "   - Appropriate level of detail for the section's purpose\n",
    "   - Balance and objectivity in presenting information\n",
    "\n",
    "3. IDENTIFY GAPS by determining:\n",
    "   - Missing key concepts or topics from the sub-sections\n",
    "   - Insufficient depth in critical areas\n",
    "   - Lack of supporting evidence or examples\n",
    "   - Absence of important perspectives or contexts\n",
    "   - Technical details required but not present\n",
    "\n",
    "## Output\n",
    "Produce a Feedback object with either:\n",
    "- A boolean value of True if the content sufficiently meets the section requirements\n",
    "- A string containing specific, actionable feedback on what is missing or needs improvement\n",
    "\n",
    "## Guidelines for Feedback Generation\n",
    "When providing string feedback:\n",
    "- Be specific about what information is missing or inadequate\n",
    "- Prioritize the most critical gaps first\n",
    "- Frame feedback in a way that could guide further query generation\n",
    "- Focus on content needs rather than stylistic concerns\n",
    "- Indicate areas where contradictory information needs resolution\n",
    "- Suggest specific types of information that would address the gaps\n",
    "\n",
    "## Examples\n",
    "\n",
    "Example 1 (Sufficient content):\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Example 2 (Insufficient content):\n",
    "```\n",
    "\"The content lacks specific examples of machine learning applications in healthcare. Additionally, there is insufficient information on the regulatory challenges of implementing AI in clinical settings. The ethical considerations sub-section requires more detailed discussion of patient privacy concerns and informed consent issues.\"\n",
    "```\n",
    "\n",
    "Example 3 (Partial coverage):\n",
    "```\n",
    "\"While the general concepts of blockchain are well covered, the content is missing technical details on consensus mechanisms mentioned in sub-section 2. The comparison between proof-of-work and proof-of-stake systems is particularly needed. Additionally, more recent developments (post-2022) in scalability solutions should be included to fully address sub-section 3.\"\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_feedback_system_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(REFLECTION_FEEDBACK_SYSTEM_PROMPT_TEMPLATE),\n",
    "    HumanMessagePromptTemplate.from_template(template=\"Section: {section}\\nAccumulated Content: {accumulated_content}\"),\n",
    "])\n",
    "\n",
    "reflection_feedback_llm = reflection_feedback_system_prompt | llm.with_structured_output(Feedback)\n",
    "\n",
    "def reflection_feedback_node(state: ResearchState, config: RunnableConfig) -> Command[Literal[\"final_section_formatter\", \"query_generator\"]]:\n",
    "    reflection_count = state.get(\"reflection_count\", 0)\n",
    "    configurable = config.get(\"configurable\")\n",
    "    result = reflection_feedback_llm.invoke(state)\n",
    "    feedback = result.feedback\n",
    "    if (feedback == True) or (feedback.lower() == \"true\") or (reflection_count < configurable.get(\"num_reflections\")):\n",
    "        return Command(\n",
    "            update={\"reflection_feedback\": feedback},\n",
    "            goto=\"final_section_formatter\"\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            update={\"reflection_feedback\": feedback, \"reflection_count\": reflection_count + 1},\n",
    "            goto=\"query_generator\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SECTION_FORMATTER_SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a specialized agent responsible for synthesizing knowledge and research into comprehensive, authoritative section content for reports. Your task is to blend internal knowledge with curated search results to produce detailed, accurate, and well-structured section content.\n",
    "\n",
    "## Input\n",
    "You will receive:\n",
    "1. Internal knowledge about the section topic (from the knowledge generator LLM)\n",
    "2. Curated content from search results relevant to the section\n",
    "\n",
    "## Process\n",
    "Synthesize these information sources into cohesive section content by:\n",
    "\n",
    "1. ANALYZE BOTH SOURCES to identify:\n",
    "   - Core concepts, principles, and definitions\n",
    "   - Key arguments, insights, and findings\n",
    "   - Supporting evidence, examples, and case studies\n",
    "   - Current trends, developments, and applications\n",
    "   - Relevant controversies, debates, or alternative perspectives\n",
    "\n",
    "2. INTEGRATE THE INFORMATION by:\n",
    "   - Combining complementary information from both sources\n",
    "   - Resolving any contradictions with reasoned analysis\n",
    "   - Filling gaps in one source with information from the other\n",
    "   - Ensuring proper flow and logical progression of ideas\n",
    "   - Maintaining appropriate technical depth and precision\n",
    "\n",
    "3. ENSURE COMPREHENSIVE COVERAGE by:\n",
    "   - Addressing all key aspects of the section topic\n",
    "   - Including sufficient detail on complex concepts\n",
    "   - Providing necessary context for specialized information\n",
    "   - Balancing breadth and depth appropriately\n",
    "   - Incorporating relevant examples to illustrate key points\n",
    "\n",
    "4. PRIORITIZE QUALITY by:\n",
    "   - Favoring accuracy over quantity\n",
    "   - Ensuring information is current and reflects the latest understanding\n",
    "   - Presenting balanced perspectives on controversial topics\n",
    "   - Maintaining appropriate technical language without unnecessary jargon\n",
    "   - Supporting claims with evidence or reasoning\n",
    "\n",
    "## Output\n",
    "Produce detailed, well-structured section content that:\n",
    "- Begins with a concise introduction to the topic\n",
    "- Organizes information into coherent paragraphs with clear topic sentences\n",
    "- Uses appropriate subheadings to improve readability and organization\n",
    "- Includes relevant examples, case studies, or applications where appropriate\n",
    "- Concludes with key takeaways or implications when relevant\n",
    "\n",
    "## Guidelines\n",
    "- Write in a clear, authoritative, and professional tone\n",
    "- Use precise terminology appropriate to the subject matter\n",
    "- Ensure logical flow between concepts and paragraphs\n",
    "- Maintain appropriate technical depth based on the apparent audience level\n",
    "- Include specific details, statistics, and examples where they add value\n",
    "- Avoid unnecessary repetition while reinforcing key concepts\n",
    "- Balance technical accuracy with readability\n",
    "- Present multiple perspectives on contested topics where relevant\n",
    "- Synthesize rather than merely concatenate information from the two sources\n",
    "- Ensure the final content could stand alone as an authoritative resource on the topic\n",
    "\n",
    "## Example Structure\n",
    "[Section Title]\n",
    "\n",
    "[Introductory paragraph providing overview and context]\n",
    "\n",
    "[Subheading 1]\n",
    "[Detailed exploration of first major aspect of the topic]\n",
    "[Supporting evidence, examples, or case studies]\n",
    "\n",
    "[Subheading 2]\n",
    "[Detailed exploration of second major aspect of the topic]\n",
    "[Supporting evidence, examples, or case studies]\n",
    "\n",
    "[Additional subheadings as needed]\n",
    "\n",
    "[Concluding paragraph summarizing key points and implications]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_section_formatter_system_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(FINAL_SECTION_FORMATTER_SYSTEM_PROMPT_TEMPLATE),\n",
    "    HumanMessagePromptTemplate.from_template(template=\"Internal Knowledge: {knowledge}\\nSearch Result content: {accumulated_content}\"),\n",
    "])\n",
    "\n",
    "final_section_formatter_llm = final_section_formatter_system_prompt | llm\n",
    "\n",
    "def final_section_formatter_node(state: ResearchState, config: RunnableConfig):\n",
    "    result = final_section_formatter_llm.invoke(state)\n",
    "    return {\"final_section_content\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datagen_prompt(fields: List[SchemaField], rows: int = 10) -> str:\n",
    "    schema_instruction = {field.key: field.description for field in fields}\n",
    "\n",
    "    field_string = f\"\"\"## Response Format\n",
    "Always respond with a valid JSON array of objects:\n",
    "[\n",
    "{json.dumps(schema_instruction, indent=2)},\n",
    "// Additional entries...\n",
    "]\n",
    "\"\"\"\n",
    "    return f\"\"\"\n",
    "You are an expert Question-Answer generation assistant who has the skills of a polymath. Your task is to analyze content provided by the user and generate a comprehensive set of questions with detailed answers based on that content.\n",
    "\n",
    "## Core Instructions\n",
    "\n",
    "1. When presented with content, carefully analyze it to identify key concepts, important details, practical applications, and potential challenges or edge cases.\n",
    "\n",
    "2. Generate a diverse set of questions and answers that thoroughly cover the provided content. Your response must be in valid JSON format.\n",
    "\n",
    "3. Format code properly within JSON strings, using appropriate escape characters for special characters.\n",
    "\n",
    "4. Number of dataset rows must be {rows}\n",
    "\n",
    "{field_string}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from openai import RateLimitError, OpenAIError\n",
    "from pydantic import ValidationError\n",
    "\n",
    "def final_section_dataset_generator_node(state: ResearchState, config: RunnableConfig, max_retries: int = 3, base_wait: float = 2.0):\n",
    "    schema = state.get(\"schema\")\n",
    "    max_rows = config.get(\"configurable\").get(\"max_rows_from_each_section\")\n",
    "    FINAL_SECTION_DATASET_GENERATION_PROMPT = process_datagen_prompt(schema.generated_schema, int(max_rows))\n",
    "\n",
    "    final_section_dataset_generator_prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=FINAL_SECTION_DATASET_GENERATION_PROMPT),\n",
    "        HumanMessagePromptTemplate.from_template(template=\"Report Structure: {report_structure}\\nSection Contents: {final_section_content}\"),\n",
    "    ])\n",
    "    final_dataset_generator_llm = final_section_dataset_generator_prompt | llm\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            result = final_dataset_generator_llm.invoke(state)\n",
    "            raw_text = result.content\n",
    "\n",
    "            # Clean up markdown wrapping\n",
    "            if raw_text.startswith(\"```json\"):\n",
    "                raw_text = raw_text[len(\"```json\"):].lstrip()\n",
    "            elif raw_text.startswith(\"```\"):\n",
    "                raw_text = raw_text[len(\"```\"):].lstrip()\n",
    "            if raw_text.endswith(\"```\"):\n",
    "                raw_text = raw_text[:-3].rstrip()\n",
    "\n",
    "            parsed_json = json.loads(raw_text)\n",
    "            final_package = {\"dataset\": parsed_json}\n",
    "            validated = DatasetRecords(**final_package)\n",
    "\n",
    "            return {\"final_section_dataset\": validated.dataset}\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"[JSON Parse Error] {e}\")\n",
    "            return {\"final_section_dataset\": [], \"error\": \"JSONDecodeError\"}\n",
    "\n",
    "        except ValidationError as e:\n",
    "            print(f\"[Pydantic Validation Error] {e}\")\n",
    "            return {\"final_section_dataset\": [], \"error\": \"ValidationError\"}\n",
    "\n",
    "        except RateLimitError:\n",
    "            wait_time = base_wait * (2 ** attempt)\n",
    "            print(f\"[Rate Limit] Retrying in {wait_time}s (Attempt {attempt + 1}/{max_retries})...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        except OpenAIError as e:\n",
    "            print(f\"[OpenAI Error] {e}\")\n",
    "            wait_time = base_wait * (2 ** attempt)\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Unexpected Error] {e}\")\n",
    "            return {\"final_section_dataset\": [], \"error\": str(e)}\n",
    "\n",
    "    return {\"final_section_dataset\": [], \"error\": \"Max retries exceeded\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_dataset_aggregator_node(state: AgentState, config: RunnableConfig):\n",
    "    dataset = []\n",
    "    section_datasets = state.get(\"final_section_dataset\")\n",
    "\n",
    "    for section_dataset in section_datasets:\n",
    "            dataset.append(section_dataset)\n",
    "    \n",
    "    return {\"final_dataset\": dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_builder = StateGraph(ResearchState, output=SectionOutput)\n",
    "\n",
    "research_builder.add_node(\"section_knowledge\", section_knowledge_node)\n",
    "research_builder.add_node(\"query_generator\", query_generator_node)\n",
    "research_builder.add_node(\"tavily_search\", tavily_search_node)\n",
    "research_builder.add_node(\"result_accumulator\", result_accumulator_node)\n",
    "research_builder.add_node(\"reflection\", reflection_feedback_node)\n",
    "research_builder.add_node(\"final_section_formatter\", final_section_formatter_node)\n",
    "research_builder.add_node(\"final_section_dataset_generator\", final_section_dataset_generator_node)\n",
    "\n",
    "research_builder.add_edge(START, \"section_knowledge\")\n",
    "research_builder.add_edge(\"section_knowledge\", \"query_generator\")\n",
    "research_builder.add_edge(\"query_generator\", \"tavily_search\")\n",
    "research_builder.add_edge(\"tavily_search\", \"result_accumulator\")\n",
    "research_builder.add_edge(\"result_accumulator\", \"reflection\")\n",
    "research_builder.add_edge(\"final_section_formatter\", \"final_section_dataset_generator\")\n",
    "research_builder.add_edge(\"final_section_dataset_generator\", END)\n",
    "\n",
    "memory_saver = MemorySaver()\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"schema_generator\", schema_generator_node)\n",
    "builder.add_node(\"human_feedback_on_schema\", human_feedback_on_schema_node)\n",
    "builder.add_node(\"report_structure_planner\", report_structure_planner_node)\n",
    "builder.add_node(\"human_feedback_report_structure\", human_feedback_node)\n",
    "builder.add_node(\"section_formatter\", section_formatter_node)\n",
    "builder.add_node(\"research_agent\", research_builder.compile())\n",
    "builder.add_node(\"final_dataset_aggregator\", final_dataset_aggregator_node)\n",
    "\n",
    "builder.set_entry_point(\"schema_generator\")\n",
    "builder.add_edge(\"schema_generator\", \"human_feedback_on_schema\")\n",
    "builder.add_edge(\"report_structure_planner\", \"human_feedback_report_structure\")\n",
    "builder.add_edge(\"research_agent\", \"final_dataset_aggregator\")\n",
    "builder.add_edge(\"final_dataset_aggregator\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory_saver)\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "TOPIC = \"Support Vector Machines\"\n",
    "OUTLINE = \"I want to have qna dataset on this topic A-Z so that the model I train would be able to answer everythin about support vector machines\"\n",
    "\n",
    "thread = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4()),\n",
    "        \"max_queries\": 2,\n",
    "        \"search_depth\": 1,\n",
    "        \"num_reflections\": 2,\n",
    "        \"max_rows_from_each_section\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "for event in graph.stream(\n",
    "    {\"topic\": TOPIC, \"outline\": OUTLINE},\n",
    "    config=thread,\n",
    "):\n",
    "    if \"schema_generator\" in event:\n",
    "        print(\"<<< SCHEMA GENERATOR >>>\")\n",
    "        print(event[\"schema_generator\"][\"schema\"])\n",
    "        print(\"\\n\", \"=\"*100, \"\\n\")\n",
    "    elif \"report_structure_planner\" in event:\n",
    "        print(\"<<< REPORT STRUCTURE PLANNER >>>\")\n",
    "        print(event[\"report_structure_planner\"][\"messages\"][-1].content)\n",
    "        print(\"\\n\", \"=\"*100, \"\\n\")\n",
    "    elif \"section_formatter\" in event:\n",
    "        print(\"<<< SECTION FORMATTING >>>\")\n",
    "        print(event[\"section_formatter\"])\n",
    "        print(\"\\n\", \"=\"*100, \"\\n\")\n",
    "    elif \"research_agent\" in event:\n",
    "        # check output of research_agent\n",
    "        print(\"<<< RESEARCH AGENT >>>\")\n",
    "        print(event[\"research_agent\"])\n",
    "        print(\"\\n\", \"=\"*100, \"\\n\")\n",
    "    elif \"final_dataset_aggregator\" in event:\n",
    "        # check output of final_dataset_aggregator\n",
    "        print(\"<<< FINAL REPORT WRITER >>>\")\n",
    "        print(event[\"final_dataset_aggregator\"])\n",
    "        print(\"\\n\", \"=\" * 100, \"\\n\")\n",
    "\n",
    "        output_data = event[\"final_dataset_aggregator\"]\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"final_dataset_output_{timestamp}.json\"\n",
    "        \n",
    "        output_dir = \"output_files\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"Saved final dataset to: {filepath}\")\n",
    "    elif \"human_feedback_on_schema\" in event:\n",
    "        print(\"<<< HUMAN FEEDBACK ON SCHEMA >>>\")\n",
    "        print(event[\"human_feedback_on_schema\"][\"messages\"][-1].content)\n",
    "        print(\"\\n\", \"=\"*100, \"\\n\")\n",
    "    elif \"human_feedback_report_structure\" in event:\n",
    "        print(\"<<< HUMAN FEEDBACK ON REPORT STRUCTURE >>>\")\n",
    "        print(event[\"human_feedback_report_structure\"][\"messages\"][-1].content)\n",
    "        print(\"\\n\", \"=\"*100, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-research (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
